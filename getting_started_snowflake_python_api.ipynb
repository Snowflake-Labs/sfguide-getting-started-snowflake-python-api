{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart: Getting Started with the Snowflake Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, import the required libraries. We'll import Snowpark, the core Snowflake Python API library, and several classes within the core library that are used to manage Snowflake objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from typing import List\n",
    "\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.core import Root,CreateMode\n",
    "from snowflake.core.database import Database\n",
    "from snowflake.core.schema import Schema\n",
    "from snowflake.core.table import Table, TableColumn, PrimaryKey\n",
    "from snowflake.core.warehouse import Warehouse\n",
    "from snowflake.core._common import CreateMode\n",
    "from snowflake.core.task import StoredProcedureCall, Task\n",
    "from snowflake.core.task.dagv1 import DAGOperation, DAG, DAGTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [Connecting to Snowflake with the Snowflake Python API](https://docs.snowflake.com/en/LIMITEDACCESS/snowflake-python-api/snowflake-python-connecting-snowflake). To get started quickly, create a file `$HOME/.snowflake/config.toml` with the following contents,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```toml\n",
    "[connections]\n",
    "[connections.default]\n",
    "account = \"YOUR ACCOUNT NAME\"\n",
    "user = \"YOUR ACCOUNT USER\"\n",
    "password = \"YOUR ACCOUNT USER PASSWORD\"\n",
    "# optional\n",
    "# warehouse = \"COMPUTE_WH\"\n",
    "# optional\n",
    "# database = \"COMPUTE_WH\"\n",
    "# optional\n",
    "# schema = \"PUBLIC\"\n",
    "```\n",
    "\n",
    "Next create a `connections_params` dictionary as show below and set the connection to use for the session,\n",
    "\n",
    "```py\n",
    "   connection_params = {\n",
    "\t\"connection_name\": \"your connection name\",\n",
    "   }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_params = {\n",
    "\t\"connection_name\": \"default\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create your Snowpark session by passing in your connection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, instantiate the `Root` class and pass in your session object as an argument. The resulting object – in this case, `root` – will be used to invoke the rest of Snowflake Python API methods and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Root(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using `root`  to create a database, schema, and table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = root.databases.create(Database(name=\"PYTHON_API_DB\"), mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to explore Snowflake objects,\n",
    "\n",
    "- Navigating to your Snowflake account in the browser and verify the objects that has been created. In this case `PYTHON_API_DB` database.\n",
    "- Using Snowflake Python API\n",
    "\n",
    "Let us use the API to list all the database objects and ensure `PYTHON_API_DB` is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_databases:List[Database] = root.databases.iter()\n",
    "for db in all_databases:\n",
    "    print(f\"{db.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TIP:\n",
    "If you use VSCode, then install [Snowflake plugin](https://marketplace.visualstudio.com/items?itemName=snowflake.snowflake-vsc) to explore all Snowflake objects from within your editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = database.schemas.create(Schema(name=\"PYTHON_API_SCHEMA\"), mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = schema.tables.create(\n",
    "\tTable(\n",
    "\t\tname=\"PYTHON_API_TABLE\", \n",
    "\t  columns=[\n",
    "\t\t\tTableColumn(name=\"TEMPERATURE\", datatype=\"int\", nullable=False), TableColumn(name=\"LOCATION\", datatype=\"string\"),\n",
    "\t\t],\n",
    "  ), \n",
    "  mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have a database, schema, and table within your Snowflake account. \n",
    "\n",
    "`table` represents a `TableResource` object. To retrieve information about the table, call `.fetch()` on the table you created above and store it an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_details = table.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.fetch()` returns a `TableModel` object, and objects of this type have several methods associated with them that can return more information about that specific Snowflake object. Let's call `.to_dict()` on `python_api_table` to view this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_details.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the dictionary above contains information about the `PYTHON_API_TABLE` table that you created earlier, including information on `columns`, `owner`, `database`, `schema` etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_details.columns.append(TableColumn(name=\"elevation\",datatype=\"int\",nullable=False,constraints=[PrimaryKey()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we define a new column using `TableColumn` and add it to the array in the TableModel that represents the column in the table. To add the column to the table, run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.create_or_update(table_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to your Snowflake account and confirm that the new column was added to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.fetch().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouses = root.warehouses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above returns the collection of warehouses associated with your session. Let's define a new warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_api_wh = Warehouse(\n",
    "    name=\"PYTHON_API_WH\",\n",
    "    warehouse_size=\"SMALL\",\n",
    "    auto_suspend=500,\n",
    ")\n",
    "\n",
    "warehouse = warehouses.create(python_api_wh,mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above defines a new warehouse and creates it in your Snowflake account. Navigate to your account to confirm that the warehouse was created.\n",
    "\n",
    "Now let's grab some information related to the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_details = warehouse.fetch()\n",
    "warehouse_details.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate through and search the warehouses in your Snowflake account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_list = warehouses.iter(like=\"PYTHON_API_WH\")\n",
    "result = next(warehouse_list)\n",
    "result.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we search for all warehouses that have a name that matches `PYTHON_API_WH`. In this case, we passed in the exact name of the warehouse we created earlier, but the `like` argument is generally a case-insensitive string that functions as a filter, with support for SQL wildcard characters like `%` and `_`.\n",
    "\n",
    "Let's now programmatically change the size of the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse = root.warehouses.create(Warehouse(\n",
    "    name=\"PYTHON_API_WH\",\n",
    "    warehouse_size=\"LARGE\",\n",
    "    auto_suspend=500,\n",
    "),mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the warehouse size was updated. You can also navigate to your Snowflake account to confirm the change in warehouse esize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse.fetch().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, delete the warehouse and close your Snowflake connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't yet have the API for manipulating stages, let us create the `TASKS_STAGE` stage using SQL,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_stage_name = f\"{database.name}.{schema.name}.TASKS_STAGE\"\n",
    "create_query = f\"CREATE OR REPLACE STAGE {tasks_stage_name}\"\n",
    "session.connection.execute_string(create_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and managing tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a couple of functions and manage them as `Task`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc(session: Session, from_table: str, to_table: str, count: int) -> str:\n",
    "  session.table(from_table).limit(count).write.save_as_table(to_table)\n",
    "  return \"Truncated table successfully created!\"\n",
    "\n",
    "def filter_by_shipmode(session: Session, mode: str) -> str:\n",
    "  session.table(\"snowflake_sample_data.tpch_sf100.lineitem\").filter(col(\"L_SHIPMODE\") == mode).limit(10).write.save_as_table(\"filter_table\")\n",
    "  return \"Filter table successfully created!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task1 = Task(\n",
    "    \"task_python_api_trunc\",\n",
    "    definition=StoredProcedureCall(trunc, stage_location=f\"@{tasks_stage_name}\", packages=[\"snowflake-snowpark-python\"]),\n",
    "    warehouse=\"COMPUTE_WH\",\n",
    "    schedule=timedelta(minutes=1)\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "    \"task_python_api_filter\",\n",
    "    definition=StoredProcedureCall(filter_by_shipmode, stage_location=f\"@{tasks_stage_name}\", packages=[\"snowflake-snowpark-python\"]),\n",
    "    warehouse=\"COMPUTE_WH\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the tasks in the specified database by adding them to the list of tasks associated with the database and schema referenced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the task into the Snowflake database\n",
    "tasks = schema.tasks\n",
    "\n",
    "trunc_task = tasks.create(task1, mode=CreateMode.or_replace)\n",
    "# should be fully qualified name\n",
    "task2.predecessors = [f\"{trunc_task.database.name}.{trunc_task.schema.name}.{trunc_task.name}\"]\n",
    "filter_task = tasks.create(task2, mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks are suspended by default when created. Start the `trunc_task` by calling `.resume()` on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_task.resume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve more information about tasks by iterating through them and printing out their name and state. Run the following cell to observe the status of each task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskiter = tasks.iter()\n",
    "for t in taskiter:\n",
    "    print(\"Name: \", t.name, \"| State: \", t.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to your Snowflake account and confirm that `trunc_task` was indeed started. After confirming, suspend it by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_task.suspend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, delete both tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_task.delete()\n",
    "filter_task.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and managing DAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines a DAG using the `DAG` constructor, and creates tasks within the DAG by calling the `DAGTask` constructor. Note that the arguments passed in to this constructor are the same ones that were passed in to the `Task` constructor in an earlier cell. We also use `>>` to specify a root task. Finally, we create the DAG in our referenced schema and deploy it to Snowflake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_name = \"python_api_dag\"\n",
    "dag = DAG(dag_name, schedule=timedelta(days=1))\n",
    "with dag:\n",
    "    dag_task1 = DAGTask(\n",
    "        \"task_python_api_trunc\",\n",
    "        StoredProcedureCall(\n",
    "            trunc,\n",
    "            stage_location=f\"@{tasks_stage_name}\",\n",
    "            packages=[\"snowflake-snowpark-python\"]),\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "    )\n",
    "    dag_task2 = DAGTask(\n",
    "        \"task_python_api_filter\",\n",
    "        StoredProcedureCall(\n",
    "            filter_by_shipmode,\n",
    "            stage_location=f\"@{tasks_stage_name}\",\n",
    "            packages=[\"snowflake-snowpark-python\"]),\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "    )\n",
    "    dag_task1 >> dag_task2\n",
    "dag_op = DAGOperation(schema)\n",
    "dag_op.deploy(dag, mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the DAG, run the root task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_op.run(dag)  # Run the root task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to your Snowflake account and confirm that the root task in the DAG was started. Once confirmed, delete the DAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_op.delete(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up all the objects that was created with this quickstart and close the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.delete()\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! In this notebook, you learned the fundamentals for managing Snowflake objects, tasks, and DAGs using the Snowflake Python API.\n",
    "\n",
    "For more information, see the following resources:\n",
    "\n",
    "* [Snowflake Documentation: Snowflake Python API](https://docs.snowflake.com/en/LIMITEDACCESS/snowflake-python-api/snowflake-python-overview)\n",
    "\n",
    "* [Snowflake Python API Reference Documentation](https://docs.snowflake.com/en/LIMITEDACCESS/snowflake-python-api/reference/0.1.0/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
